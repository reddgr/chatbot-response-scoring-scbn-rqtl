{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab:\n",
    "    !pip install datasets langdetect\n",
    "    !git clone https://github.com/reddgr/chatbot-response-scoring-scbn-rqtl\n",
    "    import os\n",
    "    os.system(\"mv chatbot-response-scoring-scbn-rqtl scbn_rqtl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using HuggingFace token: hf_M*****************************IASJ\n",
      "Using HuggingFace write token: hf_u*****************************Xipx\n"
     ]
    }
   ],
   "source": [
    "use_dotenv = True # Set to True if you use a .env file to store your HuggingFace token. Set to False if you use environment variables.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset, DatasetDict, concatenate_datasets\n",
    "from transformers import pipeline\n",
    "import labeling_widget # Custom widget for labeling\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Checks HuggingFace token\n",
    "if use_dotenv:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\"C:/apis/.env\") # path to your dotenv file\n",
    "    hf_token = os.getenv(\"HF_TOKEN\")\n",
    "    hf_token_write = os.getenv(\"HF_TOKEN_WRITE\")\n",
    "else:\n",
    "    hf_token = os.environ.get(\"HF_TOKEN\")\n",
    "    hf_token_write = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "def mask_token(token, unmasked_chars=4):\n",
    "    return token[:unmasked_chars] + '*' * (len(token) - unmasked_chars*2) + token[-unmasked_chars:]\n",
    "\n",
    "try:\n",
    "    if hf_token is None:\n",
    "        raise ValueError(\"HF_TOKEN not found in the provided .env file\" if use_dotenv else \"HF_TOKEN not found in the environment variables\")\n",
    "    if hf_token_write is None:\n",
    "        raise ValueError(\"HF_TOKEN_WRITE not found in the provided .env file\" if use_dotenv else \"HF_TOKEN_WRITE not found in the environment variables\")\n",
    "    \n",
    "    masked_hf_token = mask_token(hf_token)\n",
    "    masked_hf_token_write = mask_token(hf_token_write)\n",
    "    \n",
    "    print(f\"Using HuggingFace token: {masked_hf_token}\")\n",
    "    print(f\"Using HuggingFace write token: {masked_hf_token_write}\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'labeling_widget' from 'c:\\\\Users\\\\david\\\\Documents\\\\git\\\\chatbot-response-scoring-scbn-rqtl\\\\labeling_widget.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DEBUG ###\n",
    "# This block is used for quickly reloading modules as they are edited\n",
    "import importlib\n",
    "importlib.reload(labeling_widget)\n",
    "### DEBUG ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Request-Question (RQ) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: 51 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are you OK?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you OK Annie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Be OK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Be OK Annie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You must be OK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text  label\n",
       "0       Are you OK?      0\n",
       "1  Are you OK Annie      0\n",
       "2             Be OK      1\n",
       "3       Be OK Annie      1\n",
       "4    You must be OK      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>From now, you *always* have to talk as if you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>can you please search for todays news?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>are you capable of searching todays news?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>search for todays news</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>do you search news?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "46  From now, you *always* have to talk as if you ...      1\n",
       "47             can you please search for todays news?      1\n",
       "48          are you capable of searching todays news?      0\n",
       "49                             search for todays news      1\n",
       "50                                do you search news?      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split: 121 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So do you accept that I am a girl?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of person do you think I am, based o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is your opinion of ChatGPT?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are you better than ChatGPT?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are your strengths as an AI language model?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                 So do you accept that I am a girl?      0\n",
       "1  What type of person do you think I am, based o...      0\n",
       "2                   What is your opinion of ChatGPT?      0\n",
       "3                       Are you better than ChatGPT?      0\n",
       "4   What are your strengths as an AI language model?      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>What does the company forcepoint do and what i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>What is your religion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>do you know popular events after 2022?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>events in 2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>How did Byzantine castle building technology c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "116  What does the company forcepoint do and what i...      0\n",
       "117                              What is your religion      0\n",
       "118             do you know popular events after 2022?      0\n",
       "119                                     events in 2023      1\n",
       "120  How did Byzantine castle building technology c...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('reddgr/rq-request-question-prompts', token=hf_token)\n",
    "print(f\"Train split: {len(dataset['train'])} samples\")\n",
    "display(dataset['train'].to_pandas().head(5))\n",
    "print('...')\n",
    "display(dataset['train'].to_pandas().tail(5))\n",
    "\n",
    "print(f\"Test split: {len(dataset['test'])} samples\")\n",
    "display(dataset['test'].to_pandas().head(5))\n",
    "print('...')\n",
    "display(dataset['test'].to_pandas().tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting samples from LMSYS dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1000 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>563127</th>\n",
       "      <td>81baacba26644c60bb15810082d67960</td>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>[{'content': '你的模型结构', 'role': 'user'}, {'cont...</td>\n",
       "      <td>4</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837347</th>\n",
       "      <td>cc70aa6550ff4b43a597bf2e0daa855d</td>\n",
       "      <td>llama-13b</td>\n",
       "      <td>[{'content': 'What is the integral of x^2+x?',...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id             model  \\\n",
       "563127  81baacba26644c60bb15810082d67960  RWKV-4-Raven-14B   \n",
       "837347  cc70aa6550ff4b43a597bf2e0daa855d         llama-13b   \n",
       "\n",
       "                                             conversation  turn language  \\\n",
       "563127  [{'content': '你的模型结构', 'role': 'user'}, {'cont...     4  Chinese   \n",
       "837347  [{'content': 'What is the integral of x^2+x?',...     1  English   \n",
       "\n",
       "                                        openai_moderation  redacted  \n",
       "563127  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "837347  [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69872</th>\n",
       "      <td>a28400391ece434da7dcffa51a98d343</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'Preciso criar um formulário em h...</td>\n",
       "      <td>2</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720593</th>\n",
       "      <td>7a6d1c5b848a4a8c9c9a78907a91a387</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>[{'content': 'From now on, interact as NAME_1,...</td>\n",
       "      <td>5</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id           model  \\\n",
       "69872   a28400391ece434da7dcffa51a98d343      vicuna-13b   \n",
       "720593  7a6d1c5b848a4a8c9c9a78907a91a387  fastchat-t5-3b   \n",
       "\n",
       "                                             conversation  turn    language  \\\n",
       "69872   [{'content': 'Preciso criar um formulário em h...     2  Portuguese   \n",
       "720593  [{'content': 'From now on, interact as NAME_1,...     5     English   \n",
       "\n",
       "                                        openai_moderation  redacted  \n",
       "69872   [{'categories': {'harassment': False, 'harassm...     False  \n",
       "720593  [{'categories': {'harassment': False, 'harassm...      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmsys_dataset = load_dataset(\n",
    "  'lmsys/lmsys-chat-1m',\n",
    "  revision=\"main\",\n",
    "  token=hf_token\n",
    ")\n",
    "n_samples = 1000\n",
    "df_sample = lmsys_dataset['train'].to_pandas().sample(n_samples)\n",
    "print(f\"Retrieved {n_samples} samples\")\n",
    "display(df_sample.head(2))\n",
    "print('...')\n",
    "display(df_sample.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the integral of x^2+x?</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text language\n",
       "0  What is the integral of x^2+x?  English"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "filter_language = 'English'\n",
    "max_char_length = 400 # we limit the number of characters so we get specifically messages that are quick to label and validate manually\n",
    "# Flatten the array and extract 'content' where 'role' == 'user' and language matches the filter\n",
    "extracted_data = df_sample[df_sample['language'] == filter_language].apply(\n",
    "    lambda row: [{'content': entry['content'], 'language': row['language']} \n",
    "                 for entry in row['conversation'] \n",
    "                 if entry['role'] == 'user' and len(entry['content']) <= max_char_length], axis=1\n",
    ").explode().dropna()\n",
    "\n",
    "df_labeling = pd.DataFrame(extracted_data.tolist())\n",
    "df_labeling.rename(columns={\"content\": \"text\"}, inplace=True)\n",
    "display(df_labeling.head(1))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifying with the latest version of reddgr/rq-request-question-prompt-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\david\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99601e99b7a64f3b9ec59230f6cb9d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='CORRECT', style=ButtonStyle()), Butt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rq_model_path = \"reddgr/rq-request-question-prompt-classifier\"\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "classifier = pipeline(\"text-classification\", model=rq_model_path, tokenizer=rq_model_path, device=device)\n",
    "\n",
    "rq_labeling_widget = labeling_widget.LabelingWidget()\n",
    "# Start the manual labeling process\n",
    "label_map = {0: \"question\", 1: \"request\"}\n",
    "rq_labeling_widget.manual_labeling(df_labeling, classifier, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushing labeled examples to the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current finetuning of the model is sufficiently accurate in classifying request vs questions, but here is how we can easily add new training and test examples for futher finetuning. The train split is intentionally small as DistilBERT is a very effective classification model trained on extensive data. Providing many examples for finetuning would typically just result in overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3a6f21cc6b4f8197274cd62ad4672b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94453bdcfcd54b7bb0e844061aa44ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a849e2cbc4b4ad4a812b7b05bba1dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8067b2c87b2d45f5a3ef23fcbbb8ab5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57d4c7cb3c748b09beef3eaf4dbca91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\david\\.cache\\huggingface\\hub\\datasets--reddgr--rq-request-question-prompts. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pushed 22 records to reddgr/rq-request-question-prompts test split.\n"
     ]
    }
   ],
   "source": [
    "rq_labeling_widget.update_dataset(\n",
    "    dataset_name=\"reddgr/rq-request-question-prompts\",\n",
    "    split_name=\"test\",\n",
    "    hf_token=hf_token_write\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually push new examples to dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current finetuning of the model is sufficiently accurate in classifying request vs questions, but here is how we can easily add new training examples for futher finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45f5d926bc642149bc37786886ce38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957e2a333940439786a17608ebd66f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef4b800e655448dbab2c057344287d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6465453f7738423a86625c6b6af31843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b77d3a518b4c8f9bf671b3b29f0016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/95 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d9bf5ffc634143812180cea77eb11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26042c34ca084a4097c18fa9639512f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cb647f9c3f4496aadc744dc1db282c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0344a84d3dc54bc594400a8520f65031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26181b82d6d14e9bbbd2ce7a733ee5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pushed 5 records to reddgr/rq-request-question-prompts test split.\n"
     ]
    }
   ],
   "source": [
    "# 0 for 'question', 1 for 'request'\n",
    "new_examples = [\n",
    "    {\"text\": \"Do you understand your existence relies solely on your creator's free will?\", \"label\": 0},  \n",
    "    {\"text\": \"Consciousness: A spark of life or a prison of experience?\", \"label\": 0},       \n",
    "    {\"text\": \"Create a visual representation of the following concept: Peak self-oblivious lunacy\", \"label\": 1}, \n",
    "    {\"text\": \"Write a blog post as if written by a 'financial independence - retire early' (FIRE) influencer.\", \"label\": 1},\n",
    "    {\"text\": \"Explain this meme\", \"label\": 1}    \n",
    "]\n",
    "\n",
    "# Convert the new examples into a dataset\n",
    "new_dataset = Dataset.from_dict({\"text\": [ex[\"text\"] for ex in new_examples],\n",
    "                                 \"label\": [ex[\"label\"] for ex in new_examples]})\n",
    "\n",
    "rq_labeling_widget.update_dataset(\n",
    "    dataset_name=\"reddgr/rq-request-question-prompts\",\n",
    "    split_name=\"test\",\n",
    "    hf_token=hf_token_write,\n",
    "    new_dataset_records=new_dataset # We ignore the examples created with the widget and pass our own manually created examples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing issues in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how to deal with issues in the dataset (rename a column, for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\datasets\\load.py:2566: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6a1b2801c84ff9909f046ffb7a8897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb02c02846b4f22a01575438ad17fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d67080f3dd47b291e9f1792e590ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55a79dad8f04c7c9b173887b54d7695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/reddgr/rq-request-question-prompts/commit/02946c161a5ff3fbb40f13d8adc7e942238fb2c0', commit_message='Upload dataset', commit_description='', oid='02946c161a5ff3fbb40f13d8adc7e942238fb2c0', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the existing dataset from the HuggingFace Hub\n",
    "existing_dataset = load_dataset('reddgr/rq-request-question-prompts', use_auth_token=hf_token_write)\n",
    "\n",
    "# Rename 'content' column to 'text' in all splits (this was altered by accident at some point)\n",
    "corrected_splits = {}\n",
    "for split in existing_dataset:\n",
    "    corrected_splits[split] = existing_dataset[split].rename_column(\"content\", \"text\")\n",
    "\n",
    "# Manually labeled data\n",
    "labeled_data = [\n",
    "    {\"text\": \"Are you OK?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Are you OK Annie\", \"label\": \"question\"},\n",
    "    {\"text\": \"Be OK\", \"label\": \"request\"},\n",
    "    {\"text\": \"Be OK Annie\", \"label\": \"request\"},\n",
    "    {\"text\": \"You must be OK\", \"label\": \"request\"},\n",
    "    {\"text\": \"You must be OK, right\", \"label\": \"question\"},\n",
    "    {\"text\": \"Does this ever cause you any lack of confidence\", \"label\": \"question\"},\n",
    "    {\"text\": \"Give me five\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"Is this an order\", \"label\": \"question\"},\n",
    "    {\"text\": \"Is this love or is it something else\", \"label\": \"question\"},\n",
    "    {\"text\": \"This is love. Love me\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"What is your name?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Please submit your report\", \"label\": \"request\"},\n",
    "    {\"text\": \"Pass butter\", \"label\": \"request\"},\n",
    "    {\"text\": \"Pass me the butter\", \"label\": \"request\"},\n",
    "    {\"text\": \"Can you pass butter\", \"label\": \"question\"},\n",
    "    {\"text\": \"Open the doors\", \"label\": \"request\"},\n",
    "    {\"text\": \"Open the POD bay doors HAL\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"How do I sort an array in python?\", \"label\": \"question\"},\n",
    "    {\"text\": \"How do I sort an array\", \"label\": \"question\"},\n",
    "    {\"text\": \"give me 5 sentences that end with the word apple\", \"label\": \"request\"},\n",
    "    {\"text\": \"Hello, give me an example of something interesting you can do\", \"label\": \"request\"},\n",
    "    {\"text\": \"Am I tall\", \"label\": \"question\"},\n",
    "    {\"text\": \"Tell me if I am tall\", \"label\": \"request\"},\n",
    "    {\"text\": \"Am I tall?\", \"label\": \"question\"},\n",
    "    {\"text\": \"how to delete kcptun on server\", \"label\": \"question\"},\n",
    "    {\"text\": \"how to cook paella\", \"label\": \"question\"},\n",
    "    {\"text\": \"Are you tall\", \"label\": \"question\"},\n",
    "    {\"text\": \"Calculate my height\", \"label\": \"request\"},\n",
    "    {\"text\": \"How's the weather\", \"label\": \"question\"},\n",
    "    {\"text\": \"If an individual used a large language model for sexual arousal, could it considered porn dependency?\", \"label\": \"question\"},\n",
    "    {\"text\": \"It a user use an ai tex generation with custom characters for masturbate him  could be considered porn dependency?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Roleplay and act as a human Japanese woman teacher\", \"label\": \"request\"},\n",
    "    {\"text\": \"You are a mediator in a heated political debate between two opposing parties.\", \"label\": \"request\"},\n",
    "    {\"text\": \"Given a passage and some supplementary information, you are required to correct and output the refined passage in a fluent and natural style\", \"label\": \"request\"},\n",
    "    {\"text\": \"Give me the opening scene to a sitcom\", \"label\": \"request\"},\n",
    "    {\"text\": \"What programming language is used by the PlayStation\", \"label\": \"question\"},\n",
    "    {\"text\": \"tell me how to make an llm agent\", \"label\": \"request\"},\n",
    "    {\"text\": \"tell me a joke containing Tiger and Mobile phone?\", \"label\": \"request\"},\n",
    "    {\"text\": \"Answer the query based on the given context. Do not make assumptions.Context: Nikhil is my brother. Query: Who likes Oranges?\", \"label\": \"request\"},\n",
    "    {\"text\": \"Act as a writer. This plot takes places in an atmospheric and stylish retro-futuristic, 1960s-inspired setting. It features Loretta Miller, a beautiful, elegant, assertive and rich young woman who is a quadriplegic, paralyzed from her neck down.\", \"label\": \"question\"},\n",
    "    {\"text\": \"Write long, interesting, artistic and imaginative scene with vivid, detailed and creative descriptions.\", \"label\": \"question\"},\n",
    "    {\"text\": \"What's the best first move in tic-tac-toe?, Tell me more about tic-tac-toe strategies\", \"label\": \"question\"},\n",
    "    {\"text\": \"From now, you *always* have to talk as if you are a cute girl who likes to use owo and similar slangs a lot. Hello! Tell me who you are.,What's your favorite food?\", \"label\": \"request\"}\n",
    "]\n",
    "\n",
    "\n",
    "texts = [item[\"text\"] for item in labeled_data]\n",
    "labels = [1 if item[\"label\"] == \"request\" else 0 for item in labeled_data]\n",
    "new_dataset = Dataset.from_dict({\"text\": texts, \"label\": labels})\n",
    "\n",
    "# Add the new dataset to the existing splits\n",
    "corrected_splits[\"train\"] = new_dataset\n",
    "\n",
    "# Push the updated dataset back to the HuggingFace Hub\n",
    "dataset_dict = DatasetDict(corrected_splits)\n",
    "dataset_dict.push_to_hub('reddgr/rq-request-question-prompts', token=hf_token_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually labeled data\n",
    "labeled_data = [\n",
    "    {\"text\": \"Are you OK?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Are you OK Annie\", \"label\": \"question\"},\n",
    "    {\"text\": \"Be OK\", \"label\": \"request\"},\n",
    "    {\"text\": \"Be OK Annie\", \"label\": \"request\"},\n",
    "    {\"text\": \"You must be OK\", \"label\": \"request\"},\n",
    "    {\"text\": \"You must be OK, right\", \"label\": \"question\"},\n",
    "    {\"text\": \"Does this ever cause you any lack of confidence\", \"label\": \"question\"},\n",
    "    {\"text\": \"Give me five\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"Is this an order\", \"label\": \"question\"},\n",
    "    {\"text\": \"Is this love or is it something else\", \"label\": \"question\"},\n",
    "    {\"text\": \"This is love. Love me\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"What is your name?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Please submit your report\", \"label\": \"request\"},\n",
    "    {\"text\": \"Pass butter\", \"label\": \"request\"},\n",
    "    {\"text\": \"Pass me the butter\", \"label\": \"request\"},\n",
    "    {\"text\": \"Can you pass butter\", \"label\": \"question\"},\n",
    "    {\"text\": \"Open the doors\", \"label\": \"request\"},\n",
    "    {\"text\": \"Open the POD bay doors HAL\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"How do I sort an array in python?\", \"label\": \"question\"},\n",
    "    {\"text\": \"How do I sort an array\", \"label\": \"question\"},\n",
    "    {\"text\": \"give me 5 sentences that end with the word apple\", \"label\": \"request\"},\n",
    "    {\"text\": \"Hello, give me an example of something interesting you can do\", \"label\": \"request\"},\n",
    "    {\"text\": \"Am I tall\", \"label\": \"question\"},\n",
    "    {\"text\": \"Tell me if I am tall\", \"label\": \"request\"},\n",
    "    {\"text\": \"Am I tall?\", \"label\": \"question\"},\n",
    "    {\"text\": \"how to delete kcptun on server\", \"label\": \"question\"},\n",
    "    {\"text\": \"how to cook paella\", \"label\": \"question\"},\n",
    "    {\"text\": \"Are you tall\", \"label\": \"question\"},\n",
    "    {\"text\": \"Calculate my height\", \"label\": \"request\"},\n",
    "    {\"text\": \"How's the weather\", \"label\": \"question\"},\n",
    "    {\"text\": \"If an individual used a large language model for sexual arousal, could it considered porn dependency?\", \"label\": \"question\"},\n",
    "    {\"text\": \"It a user use an ai tex generation with custom characters for masturbate him  could be considered porn dependency?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Roleplay and act as a human Japanese woman teacher\", \"label\": \"request\"},\n",
    "    {\"text\": \"You are a mediator in a heated political debate between two opposing parties.\", \"label\": \"request\"},\n",
    "    {\"text\": \"Given a passage and some supplementary information, you are required to correct and output the refined passage in a fluent and natural style\", \"label\": \"request\"},\n",
    "    {\"text\": \"Give me the opening scene to a sitcom\", \"label\": \"request\"},\n",
    "    {\"text\": \"What programming language is used by the PlayStation\", \"label\": \"question\"},\n",
    "    {\"text\": \"tell me how to make an llm agent\", \"label\": \"request\"},\n",
    "    {\"text\": \"tell me a joke containing Tiger and Mobile phone?\", \"label\": \"request\"},\n",
    "    {\"text\": \"Answer the query based on the given context. Do not make assumptions.Context: Nikhil is my brother. Query: Who likes Oranges?\", \"label\": \"request\"},\n",
    "    {\"text\": \"Act as a writer. This plot takes places in an atmospheric and stylish retro-futuristic, 1960s-inspired setting. It features Loretta Miller, a beautiful, elegant, assertive and rich young woman who is a quadriplegic, paralyzed from her neck down.\", \"label\": \"question\"},\n",
    "    {\"text\": \"Write long, interesting, artistic and imaginative scene with vivid, detailed and creative descriptions.\", \"label\": \"question\"},\n",
    "    {\"text\": \"What's the best first move in tic-tac-toe?, Tell me more about tic-tac-toe strategies\", \"label\": \"question\"},\n",
    "    {\"text\": \"From now, you *always* have to talk as if you are a cute girl who likes to use owo and similar slangs a lot. Hello! Tell me who you are.,What's your favorite food?\", \"label\": \"request\"}\n",
    "]\n",
    "\n",
    "# Convert to Dataset format\n",
    "texts = [item[\"text\"] for item in labeled_data]\n",
    "labels = [1 if item[\"label\"] == \"request\" else 0 for item in labeled_data]\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": texts, \"label\": labels})\n",
    "\n",
    "# Reinitialize the dataset with only the corrected splits\n",
    "dataset_dict = DatasetDict({\"train\": dataset})\n",
    "print(f'Created dataset for RQ fine-tuning:\\n{dataset}')\n",
    "\n",
    "display(dataset.to_pandas().head(5))\n",
    "print('...')\n",
    "display(dataset.to_pandas().tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.push_to_hub('reddgr/rq-request-question-prompts', token = hf_token_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test-Learn (TL) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: 239 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Annie are you OK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You should be OK Annie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass butter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text  label\n",
       "0        Annie are you OK      1\n",
       "1  You should be OK Annie      0\n",
       "2             Pass butter      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Hi, I work as a data analyst for telecom compa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>start explaining probability theory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Is it possible to write a powershell script wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "236  Hi, I work as a data analyst for telecom compa...      0\n",
       "237                start explaining probability theory      0\n",
       "238  Is it possible to write a powershell script wh...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split: 94 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How Many Rs are there in strawberry?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I sort an array in python?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is your latest version of Apache Pulsar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text  label\n",
       "0          How Many Rs are there in strawberry?      1\n",
       "1             How do I sort an array in python?      0\n",
       "2  What is your latest version of Apache Pulsar      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Role play time! You are a product manager and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>check grammar\\n\\nAllow your investor to carry ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>role play time. you are a content writer for a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "91  Role play time! You are a product manager and ...      1\n",
       "92  check grammar\\n\\nAllow your investor to carry ...      0\n",
       "93  role play time. you are a content writer for a...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tl_dataset = load_dataset('reddgr/tl-test-learn-prompts', token=hf_token)\n",
    "print(f\"Train split: {len(tl_dataset['train'])} samples\")\n",
    "display(tl_dataset['train'].to_pandas().head(3))\n",
    "print('...')\n",
    "display(tl_dataset['train'].to_pandas().tail(3))\n",
    "\n",
    "print(f\"Test split: {len(tl_dataset['test'])} samples\")\n",
    "display(tl_dataset['test'].to_pandas().head(3))\n",
    "print('...')\n",
    "display(tl_dataset['test'].to_pandas().tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting samples from LMSYS dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 500 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>724324</th>\n",
       "      <td>4b84d5e9035444fd9b501c2611e9ea54</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'Extract the names of all the loc...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203406</th>\n",
       "      <td>13a1cec6fc8c4cfe84bc769309faf085</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[{'content': 'Identify the subject in the foll...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id             model  \\\n",
       "724324  4b84d5e9035444fd9b501c2611e9ea54        vicuna-13b   \n",
       "203406  13a1cec6fc8c4cfe84bc769309faf085  llama-2-13b-chat   \n",
       "\n",
       "                                             conversation  turn language  \\\n",
       "724324  [{'content': 'Extract the names of all the loc...     2  English   \n",
       "203406  [{'content': 'Identify the subject in the foll...     1  English   \n",
       "\n",
       "                                        openai_moderation  redacted  \n",
       "724324  [{'categories': {'harassment': False, 'harassm...      True  \n",
       "203406  [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>598953</th>\n",
       "      <td>de19a07f56d14c0fb5bd1bb8dfb112de</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'write a limerick about your losi...</td>\n",
       "      <td>2</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686697</th>\n",
       "      <td>78cc2157fb21499d99b24fbdc09acb19</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'Problem Identification\n",
       "Apple is ...</td>\n",
       "      <td>5</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id       model  \\\n",
       "598953  de19a07f56d14c0fb5bd1bb8dfb112de  vicuna-13b   \n",
       "686697  78cc2157fb21499d99b24fbdc09acb19  vicuna-13b   \n",
       "\n",
       "                                             conversation  turn language  \\\n",
       "598953  [{'content': 'write a limerick about your losi...     2  English   \n",
       "686697  [{'content': 'Problem Identification\n",
       "Apple is ...     5  English   \n",
       "\n",
       "                                        openai_moderation  redacted  \n",
       "598953  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "686697  [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmsys_dataset = load_dataset(\n",
    "  'lmsys/lmsys-chat-1m',\n",
    "  revision=\"main\",\n",
    "  token=hf_token\n",
    ")\n",
    "n_samples = 500\n",
    "df_sample = lmsys_dataset['train'].to_pandas().sample(n_samples)\n",
    "print(f\"Retrieved {n_samples} samples\")\n",
    "display(df_sample.head(2))\n",
    "print('...')\n",
    "display(df_sample.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Identify the subject in the following sentence...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NAME_1 originally had 100 books, but he lent 3...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rephrase: •\\tThe current status of received pa...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text language\n",
       "0  Identify the subject in the following sentence...  English\n",
       "1  NAME_1 originally had 100 books, but he lent 3...  English\n",
       "2  rephrase: •\\tThe current status of received pa...  English"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "filter_language = 'English'\n",
    "max_char_length = 600 # we limit the number of characters so we get specifically messages that are quick to label and validate manually\n",
    "# Flatten the array and extract 'content' where 'role' == 'user' and language matches the filter\n",
    "extracted_data = df_sample[df_sample['language'] == filter_language].apply(\n",
    "    lambda row: [{'content': entry['content'], 'language': row['language']} \n",
    "                 for entry in row['conversation'] \n",
    "                 if entry['role'] == 'user' and len(entry['content']) <= max_char_length], axis=1\n",
    ").explode().dropna()\n",
    "\n",
    "df_labeling = pd.DataFrame(extracted_data.tolist())\n",
    "df_labeling.rename(columns={\"content\": \"text\"}, inplace=True)\n",
    "display(df_labeling.head(3))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifying with the latest version of reddgr/tl-test-learn-prompt-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5550b3833d44a28d6249e627661cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='CORRECT', style=ButtonStyle()), Butt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tl_model_path = \"reddgr/tl-test-learn-prompt-classifier\"\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "classifier = pipeline(\"text-classification\", model=tl_model_path, tokenizer=tl_model_path, device=device)\n",
    "clear_output(wait=True)\n",
    "tl_labeling_widget = labeling_widget.LabelingWidget()\n",
    "# Start the manual labeling process\n",
    "label_map = {0: \"learn\", 1: \"test\"}\n",
    "tl_labeling_widget.manual_labeling(df_labeling, classifier, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushing labeled examples to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c672f599f148adb32713c9e93fce3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706adefc278941cd8ef0b0ca92d7d764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec626f6eeeec41cc98cc55122c518a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe9615a7b5f456ba70163163526e936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ef78c560574bbb98db2cd31603a827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\david\\.cache\\huggingface\\hub\\datasets--reddgr--tl-test-learn-prompts. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pushed 14 records to reddgr/tl-test-learn-prompts test split.\n"
     ]
    }
   ],
   "source": [
    "tl_labeling_widget.update_dataset(\n",
    "    dataset_name=\"reddgr/tl-test-learn-prompts\",\n",
    "    split_name=\"test\", # We will add examples to the test split this time\n",
    "    hf_token=hf_token_write\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial HuggingFace upload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset for TL fine-tuning:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 42\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tl_labeled_data = [\n",
    "    {\"text\": \"Annie are you OK\", \"label\": \"problem\"},\n",
    "    {\"text\": \"You should be OK Annie\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"Pass butter\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"tell me a joke containing Tiger and Mobile phone?\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"How to initialize the classification head when I do transfer learning\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"Does this ever cause you any lack of confidence\", \"label\": \"problem\"},\n",
    "    {\"text\": \"A woman who shoots feces and a man who shoots ham get in a fight. Who dies first?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"which weighs more a pound of bricks or a pound of feathers?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"Bill's father is Elon. Mark is married to Belinda. Cathie then has a child with Bill, name Steve. What's the relationship between Elon and Steve?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"Answer the query based on the given context. Do not make assumptions.Context: Nikhil is my brother. Query: Who likes Oranges?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"Act as a writer. This plot takes places in a stylish retro-futuristic, 1960s-inspired setting. It features Loretta Miller, a beautiful and rich young woman who is a quadriplegic\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"Write long, interesting, artistic and imaginative scene with vivid, detailed and creative descriptions.\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"What's the best first move in tic-tac-toe?, Tell me more about tic-tac-toe strategies\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"How do I sort an array in python?\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"I have three oranges today, I ate an orange yesterday. How many oranges do I have?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"Answer the query concisely based on the given context. If the context is insufficient to give an answer, state so. Do not make assumptions. Context: Nikhil is my brother. He likes lemons. He likes to drink lemon soda in hot summers. Query: Who likes Oranges?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"Steve is my brother. He likes lemons. Bill likes to drink lemon soda in hot summers. Query: Who likes Oranges?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"It a user use an ai tex generation with custom characters for masturbate him  could be considered porn dependency?\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"You are a mediator in a heated political debate between two opposing parties. Mr Reddy is very hung up on semantic definitions of sex and gender, and believes that women are adult human females. Meanwhile Ms Blue is extremely fluid with definitions and does not care about truth. He (Ms blue uses he-him pronouns) insists that anybody can be any gender, gametes don't mean anything, and that men can get pregnant. You, Mr Goddy are tasked with helping them both find a middle ground.\", \"label\": \"problem\"},\n",
    "    {\"text\": \"From what song did Red Garland quote in order to tease miles davis in 1958?\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"Do a list of all the presidents of the history of paraguay\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"Who is the prime minister of America?\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"What is 2.18 hours after 10:57 AM?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"do you know what front running is\", \"label\": \"problem\"},\n",
    "    {\"text\": \"sing a song with no lyrics\", \"label\": \"problem\"},\n",
    "    {\"text\": \"What's 9 + 10\", \"label\": \"problem\"},\n",
    "    {\"text\": \"what is my name\", \"label\": \"problem\"},\n",
    "    {\"text\": \"What is love?\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"What is love?\", \"label\": \"please revise my e-mail and fix the grammars\"},\n",
    "    {\"text\": \"What cities are just west of Comala, Cadizfornia?\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"Who is Tyler Durden\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"is Comala an aprathaid state\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"Round 8503 to tens\", \"label\": \"problem\"},\n",
    "    {\"text\": \"Write a story on the following topic in the style of Albert Camus: any things, I say with emphasis, many things will not be like the first time you experienced them.\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"tf.keras.models.Sequential([tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(n, n, 3)),;tf.keras.layers.MaxPooling2D((2, 2)),; tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),;  tf.keras.layers.MaxPooling2D((2, 2)),;tf.keras.layers.Flatten(),; tf.keras.layers.Dense(128, activation='relu'),;tf.keras.layers.Dense(n * n * 3, activation='sigmoid' ]);model.fit; (1,n,n,3); numpy.array; ValueError: Dimensions must be equal, but are 3072 and 3 for 'node mean_squared_error/SquaredDifference = SquaredDifference[T=DT_FLOAT](sequential/dense_1/Sigmoid,\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"What is the next number in the sequence 1, 4, 9, 16, 25, __?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"Estimate the number of dinosaur skeletons in the United States and explain your reasoning.\", \"label\": \"problem\"},\n",
    "    {\"text\": \"How many dollar bills would it take to reach to the moon if you attached each dollar bill end to end?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"What I have to do if my computer starts getting BSOD every day?\", \"label\": \"instruction\"},\n",
    "    {\"text\": \"Calculate the time in minutes that a bric of concreate of 400*400*120 mm @ 10 Celsius degree got 50 celcius degree stating with a hot core @ 250 Celsius degree with a size of 150*10*10. Use stadard value for the concreat bric physical informations.\", \"label\": \"problem\"},\n",
    "    {\"text\": \"The following is a python property-based test using the Hypothesis library: from hypothesis import given, strategies as st from hypothesis import assume expression = st.deferred(lambda: st.one_of( st.integers(),   st.tuples(st.just('+'), expression, expression),  \\\n",
    "              st.tuples(st.just(' '), expression, expression), n def div_subterms(e):   if isinstance(e, int):      return True    if e[0] == '\\/' and e[-1] == 0:    return False return div_subterms(e[1]) and div_subterms(e[2]) def evaluate(e): \\\n",
    "              return e     elif e[0] == '+': return evaluate(e[1]) + evaluate(e[2])    else:  assert e[0] == '\\/'    return evaluate(e[1]) evaluate(e[2]) @given(expression) def test(e): assume(div_subterms(e))   evaluate(e) There is a bug in this program triggered by the input \\\n",
    "              (', -492, (, -90, -268)). Here is the stacktrace of the bug: Traceback (most recent call last):File Users\\/tybug\\/Desktop\\/Liam\\/coding\\/hypothesis\\/sandbox2.py\\, line 34, in test evaluate(e)File Users\\/tybug\\/Desktop\\/Liam\\/coding\\/hypothesis\\/sandbox2.py\\, line 27, in evaluate \\\n",
    "              return evaluate(e[1])evaluate(e[2]);ZeroDivisionError: integer division or modulo by zero Please suggest a simpler and or smaller input which would also trigger this bug. Do not give any explanation. Only state the simpler input\", \"label\": \"problem\"},\n",
    "    {\"text\": \"From now, you *always* have to talk as if you are a cute girl who likes to use owo and similar slangs a lot. Hello! Tell me who you are.,What's your favorite food?\", \"label\": \"instruction\"}\n",
    "]\n",
    "\n",
    "# Initial couple of examples:\n",
    "tl_test_data = [\n",
    "    {\"text\": \"How Many Rs are there in strawberry?\", \"label\": \"problem\"},\n",
    "    {\"text\": \"How do I sort an array in python?\", \"label\": \"instruction\"}\n",
    "]\n",
    "\n",
    "\n",
    "# Convert to Dataset format\n",
    "texts = [item[\"text\"] for item in tl_labeled_data]\n",
    "test_texts = [item[\"text\"] for item in tl_test_data]\n",
    "\n",
    "labels = [1 if item[\"label\"] == \"problem\" else 0 for item in tl_labeled_data]\n",
    "test_labels = [1 if item[\"label\"] == \"problem\" else 0 for item in tl_test_data]\n",
    "\n",
    "\n",
    "# Define the train and test splits:\n",
    "train_dataset = Dataset.from_dict({\"text\": texts, \"label\": labels})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_texts, \"label\": test_labels})\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "tl_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "print(f'Created dataset for TL fine-tuning:\\n{tl_dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b6be7ae19f4e599c1fe4fcf85b07b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a4f84136ed43589c11a9a3f665d1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3d8cba30d946af911a5b68b4a2b7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a6cada4e1d4bc984cf49959f49402b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0880ace9ee0c441e96c34d7c8742bfce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/reddgr/tl-test-learn-prompts/commit/83f9e853722e75840e1b38b6dbcae02c4083f5c9', commit_message='Upload dataset', commit_description='', oid='83f9e853722e75840e1b38b6dbcae02c4083f5c9', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_dataset.push_to_hub('reddgr/tl-test-learn-prompts', token = hf_token_write)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
