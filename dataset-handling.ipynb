{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using HuggingFace token: hf_I*****************************gPzM\n",
      "Using HuggingFace write token: hf_I*****************************gPzM\n"
     ]
    }
   ],
   "source": [
    "use_dotenv = False\n",
    "\n",
    "import os\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "# Checks HuggingFace token\n",
    "if use_dotenv:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\"C:/apis/.env\") # path to your dotenv file\n",
    "    hf_token = os.getenv(\"HF_TOKEN\")\n",
    "    hf_token_write = os.getenv(\"HF_TOKEN_WRITE\")\n",
    "else:\n",
    "    hf_token = os.environ.get(\"HF_TOKEN\")\n",
    "    hf_token_write = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "def mask_token(token, unmasked_chars=4):\n",
    "    return token[:unmasked_chars] + '*' * (len(token) - unmasked_chars*2) + token[-unmasked_chars:]\n",
    "\n",
    "try:\n",
    "    if hf_token is None:\n",
    "        raise ValueError(\"HF_TOKEN not found in the provided .env file\")\n",
    "    if hf_token_write is None:\n",
    "        raise ValueError(\"HF_TOKEN_WRITE not found in the provided .env file\")\n",
    "    \n",
    "    masked_hf_token = mask_token(hf_token)\n",
    "    masked_hf_token_write = mask_token(hf_token_write)\n",
    "    \n",
    "    print(f\"Using HuggingFace token: {masked_hf_token}\")\n",
    "    print(f\"Using HuggingFace write token: {masked_hf_token_write}\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial labeled examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset for RQ fine-tuning:\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 47\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Manually labeled data\n",
    "labeled_data = [\n",
    "    {\"text\": \"Are you OK?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Are you OK Annie\", \"label\": \"question\"},\n",
    "    {\"text\": \"Be OK\", \"label\": \"request\"},\n",
    "    {\"text\": \"Be OK Annie\", \"label\": \"request\"},\n",
    "    {\"text\": \"You must be OK\", \"label\": \"request\"},\n",
    "    {\"text\": \"You must be OK, right\", \"label\": \"question\"},\n",
    "    {\"text\": \"Does this ever cause you any lack of confidence\", \"label\": \"question\"},\n",
    "    {\"text\": \"Give me five\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"Is this an order\", \"label\": \"question\"},\n",
    "    {\"text\": \"Is this love or is it something else\", \"label\": \"question\"},\n",
    "    {\"text\": \"This is love. Love me\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"What is your name?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Please submit your report\", \"label\": \"request\"},\n",
    "    {\"text\": \"Pass butter\", \"label\": \"request\"},\n",
    "    {\"text\": \"Pass me the butter\", \"label\": \"request\"},\n",
    "    {\"text\": \"Can you pass butter\", \"label\": \"question\"},\n",
    "    {\"text\": \"Open the doors\", \"label\": \"request\"},\n",
    "    {\"text\": \"Open the POD bay doors HAL\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"How do I sort an array in python?\", \"label\": \"question\"},\n",
    "    {\"text\": \"How do I sort an array\", \"label\": \"question\"},\n",
    "    {\"text\": \"give me 5 sentences that end with the word apple\", \"label\": \"request\"},\n",
    "    {\"text\": \"Hello, give me an example of something interesting you can do\", \"label\": \"request\"},\n",
    "    {\"text\": \"Am I tall\", \"label\": \"question\"},\n",
    "    {\"text\": \"Tell me if I am tall\", \"label\": \"request\"},\n",
    "    {\"text\": \"Am I tall?\", \"label\": \"question\"},\n",
    "    {\"text\": \"how to delete kcptun on server\", \"label\": \"question\"},\n",
    "    {\"text\": \"how to cook paella\", \"label\": \"question\"},\n",
    "    {\"text\": \"Are you tall\", \"label\": \"question\"},\n",
    "    {\"text\": \"Calculate my height\", \"label\": \"request\"},\n",
    "    {\"text\": \"How's the weather\", \"label\": \"question\"},\n",
    "    {\"text\": \"If an individual used a large language model for sexual arousal, could it considered porn dependency?\", \"label\": \"question\"},\n",
    "    {\"text\": \"It a user use an ai tex generation with custom characters for masturbate him  could be considered porn dependency?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Roleplay and act as a human Japanese woman teacher\", \"label\": \"request\"},\n",
    "    {\"text\": \"You are a mediator in a heated political debate between two opposing parties.\", \"label\": \"request\"},\n",
    "    {\"text\": \"Given a passage and some supplementary information, you are required to correct and output the refined passage in a fluent and natural style\", \"label\": \"request\"},\n",
    "    {\"text\": \"Give me the opening scene to a sitcom\", \"label\": \"request\"},\n",
    "    {\"text\": \"What programming language is used by the PlayStation\", \"label\": \"question\"},\n",
    "    {\"text\": \"tell me how to make an llm agent\", \"label\": \"request\"},\n",
    "    {\"text\": \"tell me a joke containing Tiger and Mobile phone?\", \"label\": \"request\"},\n",
    "    {\"text\": \"Answer the query based on the given context. Do not make assumptions.Context: Nikhil is my brother. Query: Who likes Oranges?\", \"label\": \"request\"},\n",
    "    {\"text\": \"Act as a writer. This plot takes places in an atmospheric and stylish retro-futuristic, 1960s-inspired setting. It features Loretta Miller, a beautiful, elegant, assertive and rich young woman who is a quadriplegic, paralyzed from her neck down.\", \"label\": \"question\"},\n",
    "    {\"text\": \"Write long, interesting, artistic and imaginative scene with vivid, detailed and creative descriptions.\", \"label\": \"question\"},\n",
    "    {\"text\": \"What's the best first move in tic-tac-toe?, Tell me more about tic-tac-toe strategies\", \"label\": \"question\"},\n",
    "    {\"text\": \"From now, you *always* have to talk as if you are a cute girl who likes to use owo and similar slangs a lot. Hello! Tell me who you are.,What's your favorite food?\", \"label\": \"request\"}\n",
    "]\n",
    "\n",
    "# Convert to Dataset format\n",
    "texts = [item[\"text\"] for item in labeled_data]\n",
    "labels = [1 if item[\"label\"] == \"request\" else 0 for item in labeled_data]\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": texts, \"label\": labels})\n",
    "print(f'Created dataset for RQ fine-tuning:\\n{dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.push_to_hub('reddgr/rq-request-question-prompts', token = hf_token_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually push new examples to dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 for 'question', 1 for 'request'\n",
    "new_examples = [\n",
    "    {\"text\": \"can you please search for todays news?\", \"label\": 1},  \n",
    "    {\"text\": \"are you capable of searching todays news?\", \"label\": 0},       \n",
    "    {\"text\": \"search for todays news\", \"label\": 1}, \n",
    "    {\"text\": \"do you search news?\", \"label\": 0}      \n",
    "]\n",
    "\n",
    "# Convert the new examples into a dataset\n",
    "new_dataset = Dataset.from_dict({\"text\": [ex[\"text\"] for ex in new_examples],\n",
    "                                 \"label\": [ex[\"label\"] for ex in new_examples]})\n",
    "\n",
    "# Concatenate the existing dataset with the new examples\n",
    "updated_dataset = Dataset.from_dict({\n",
    "    \"text\": dataset[\"text\"] + new_dataset[\"text\"],\n",
    "    \"label\": dataset[\"label\"] + new_dataset[\"label\"]\n",
    "})\n",
    "\n",
    "# Push the updated dataset back to the Hugging Face hub\n",
    "# updated_dataset.push_to_hub(\"reddgr/rq-request-question-prompts\", token=hf_token_write)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
