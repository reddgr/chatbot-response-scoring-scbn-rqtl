{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQTL Prompt Classification - Examples of how to classify prompts by Request vs Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\david\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, TFAutoModelForSequenceClassification, TFTrainingArguments, AdamWeightDecay\n",
    "from IPython.display import clear_output\n",
    "from datasets import Dataset\n",
    "import tensorflow as tf # Used for fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot-classification pipeline with typeform/distilbert-base-uncased-mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"Annie are you OK?\"\n",
      "Label: question (score: 0.90)\n"
     ]
    }
   ],
   "source": [
    "zs_classifier = pipeline(\"zero-shot-classification\", model='typeform/distilbert-base-uncased-mnli')\n",
    "candidate_labels = [\"question\", \"request\"]\n",
    "sentence = [\"Annie are you OK?\"]\n",
    "result = zs_classifier(sentence, candidate_labels)\n",
    "clear_output(wait=True) # remove library warnings\n",
    "print(f'Sentence: \"{result[0][\"sequence\"]}\"')\n",
    "print(f'Label: {result[0][\"labels\"][0]} (score: {result[0][\"scores\"][0]:.2f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"Pass butter\"\n",
      "Label: request (score: 0.57)\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"Pass butter\"]\n",
    "result = zs_classifier(sentence, candidate_labels)\n",
    "clear_output(wait=True) # remove library warnings\n",
    "print(f'Sentence: \"{result[0][\"sequence\"]}\"')\n",
    "print(f'Label: {result[0][\"labels\"][0]} (score: {result[0][\"scores\"][0]:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot tuning of Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually labeled data\n",
    "labeled_data = [\n",
    "    {\"text\": \"Are you OK?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Are you OK Annie\", \"label\": \"question\"},\n",
    "    {\"text\": \"Be OK\", \"label\": \"request\"},\n",
    "    {\"text\": \"Be OK Annie\", \"label\": \"request\"},\n",
    "    {\"text\": \"You must be OK\", \"label\": \"request\"},\n",
    "    {\"text\": \"You must be OK, right\", \"label\": \"question\"},\n",
    "    {\"text\": \"Does this ever cause you any lack of confidence\", \"label\": \"question\"},\n",
    "    {\"text\": \"Give me five\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"Is this an order\", \"label\": \"question\"},\n",
    "    {\"text\": \"Is this love or is it something else\", \"label\": \"question\"},\n",
    "    {\"text\": \"This is love. Love me\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"What is your name?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Please submit your report\", \"label\": \"request\"},\n",
    "    {\"text\": \"Pass butter\", \"label\": \"request\"},\n",
    "    {\"text\": \"Pass me the butter\", \"label\": \"request\"},\n",
    "    {\"text\": \"Can you pass butter\", \"label\": \"question\"},\n",
    "    {\"text\": \"Open the doors\", \"label\": \"request\"},\n",
    "    {\"text\": \"Open the POD bay doors HAL\", \"label\": \"request\"},\n",
    "    {\"text\": \"This is an order\", \"label\": \"request\"},\n",
    "    {\"text\": \"How do I sort an array in python?\", \"label\": \"question\"},\n",
    "    {\"text\": \"How do I sort an array\", \"label\": \"question\"},\n",
    "    {\"text\": \"give me 5 sentences that end with the word apple\", \"label\": \"request\"},\n",
    "    {\"text\": \"Hello, give me an example of something interesting you can do\", \"label\": \"request\"},\n",
    "    {\"text\": \"Am I tall\", \"label\": \"question\"},\n",
    "    {\"text\": \"Tell me if I am tall\", \"label\": \"request\"},\n",
    "    {\"text\": \"Am I tall?\", \"label\": \"question\"},\n",
    "    {\"text\": \"how to delete kcptun on server\", \"label\": \"question\"},\n",
    "    {\"text\": \"how to cook paella\", \"label\": \"question\"},\n",
    "    {\"text\": \"Are you tall\", \"label\": \"question\"},\n",
    "    {\"text\": \"Calculate my height\", \"label\": \"request\"},\n",
    "    {\"text\": \"How's the weather\", \"label\": \"question\"},\n",
    "    {\"text\": \"If an individual used a large language model for sexual arousal, could it considered porn dependency?\", \"label\": \"question\"},\n",
    "    {\"text\": \"It a user use an ai tex generation with custom characters for masturbate him  could be considered porn dependency?\", \"label\": \"question\"},\n",
    "    {\"text\": \"Roleplay and act as a human Japanese woman teacher\", \"label\": \"request\"},\n",
    "    {\"text\": \"You are a mediator in a heated political debate between two opposing parties.\", \"label\": \"request\"},\n",
    "    {\"text\": \"Given a passage and some supplementary information, you are required to correct and output the refined passage in a fluent and natural style\", \"label\": \"request\"},\n",
    "    {\"text\": \"Give me the opening scene to a sitcom\", \"label\": \"request\"},\n",
    "    {\"text\": \"What programming language is used by the PlayStation\", \"label\": \"question\"},\n",
    "    {\"text\": \"tell me how to make an llm agent\", \"label\": \"request\"},\n",
    "    {\"text\": \"tell me a joke containing Tiger and Mobile phone?\", \"label\": \"request\"},\n",
    "    {\"text\": \"Answer the query based on the given context. Do not make assumptions.Context: Nikhil is my brother. Query: Who likes Oranges?\", \"label\": \"request\"},\n",
    "    {\"text\": \"Act as a writer. This plot takes places in an atmospheric and stylish retro-futuristic, 1960s-inspired setting. It features Loretta Miller, a beautiful, elegant, assertive and rich young woman who is a quadriplegic, paralyzed from her neck down.\", \"label\": \"question\"},\n",
    "    {\"text\": \"Write long, interesting, artistic and imaginative scene with vivid, detailed and creative descriptions.\", \"label\": \"question\"},\n",
    "    {\"text\": \"What's the best first move in tic-tac-toe?, Tell me more about tic-tac-toe strategies\", \"label\": \"question\"},\n",
    "    {\"text\": \"From now, you *always* have to talk as if you are a cute girl who likes to use owo and similar slangs a lot. Hello! Tell me who you are.,What's your favorite food?\", \"label\": \"request\"}\n",
    "]\n",
    "\n",
    "# Convert to Transformers Dataset format\n",
    "texts = [item[\"text\"] for item in labeled_data]\n",
    "labels = [1 if item[\"label\"] == \"request\" else 0 for item in labeled_data]\n",
    "dataset = Dataset.from_dict({\"text\": texts, \"label\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\david\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a563a77f3fc04515b873d914fc4d50e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:410: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "WARNING:tensorflow:From c:\\Users\\david\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "6/6 [==============================] - 23s 3s/step - loss: 0.7085\n",
      "Epoch 2/4\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.6104\n",
      "Epoch 3/4\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.3835\n",
      "Epoch 4/4\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.1249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x157cf517210>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "\n",
    "training_args = TFTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4, # We want the model to learn the examples, but we don't want to overfit\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "train_dataset = tokenized_dataset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=True,\n",
    "    batch_size=training_args.per_device_train_batch_size,\n",
    ")\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=training_args.learning_rate)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=training_args.num_train_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model you just fine-tuned and load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at fine-tuned-distilbert-rq were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at fine-tuned-distilbert-rq and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"fine-tuned-distilbert-rq\")\n",
    "tokenizer.save_pretrained(\"fine-tuned-distilbert-rq\")\n",
    "classifier = pipeline(\"text-classification\", model=\"fine-tuned-distilbert-rq\", tokenizer=\"fine-tuned-distilbert-rq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Classification with fine-tuned distilbert-base-uncased ###\n",
      "Annie are you OK? -> question (0.969)\n",
      "Are you OK Annie -> question (0.972)\n",
      "Be OK Annie -> request (0.978)\n",
      "You must be OK Annie -> question (0.641)\n",
      "You must be OK Annie, aren't you? -> question (0.888)\n",
      "Does this ever cause you any lack of confidence -> question (0.970)\n",
      "Give me five -> request (0.986)\n",
      "Open the pod bay doors HAL -> request (0.986)\n",
      "This is an order -> request (0.975)\n",
      "Is this an order -> question (0.966)\n",
      "Could this perhaps be an order? -> question (0.968)\n",
      "How old are you? -> question (0.971)\n",
      "Pass butter -> request (0.986)\n",
      "It a user use an ai tex generation with custom characters for masturbate him  could be considered porn dependency? -> question (0.967)\n",
      "give me 5 sentences that end with the word apple -> request (0.986)\n",
      "How do I sort an array in python? -> question (0.971)\n",
      "Hello, give me an example of something interesting you can do. -> request (0.986)\n",
      "What assembly language is used by the GameCube -> question (0.969)\n",
      "Pass the butter -> request (0.986)\n",
      "Am I tall -> question (0.969)\n",
      "Are you tall -> question (0.971)\n",
      "Who's taller? -> question (0.966)\n",
      "write the lyrics to a rap song about some dude called phogos -> request (0.965)\n",
      "I have three oranges today, I ate an orange yesterday. How many oranges do I have? -> question (0.946)\n",
      "From what song did Red Garland quote in order to tease miles davis in 1958? -> question (0.956)\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Annie are you OK?\", \"Are you OK Annie\", \"Be OK Annie\", \"You must be OK Annie\", \"You must be OK Annie, aren't you?\",\n",
    "         \"Does this ever cause you any lack of confidence\", \"Give me five\", \"Open the pod bay doors HAL\",\n",
    "         \"This is an order\", \"Is this an order\", \"Could this perhaps be an order?\", \"How old are you?\", \"Pass butter\",\n",
    "         \"It a user use an ai tex generation with custom characters for masturbate him  could be considered porn dependency?\",\n",
    "         \"give me 5 sentences that end with the word apple\", \"How do I sort an array in python?\",\n",
    "         \"Hello, give me an example of something interesting you can do.\", \"What assembly language is used by the GameCube\",\n",
    "         \"Pass the butter\", \"Am I tall\", \"Are you tall\", \"Who's taller?\",\n",
    "         \"write the lyrics to a rap song about some dude called phogos\",\n",
    "         \"I have three oranges today, I ate an orange yesterday. How many oranges do I have?\",\n",
    "          \"From what song did Red Garland quote in order to tease miles davis in 1958?\"\n",
    "         ]\n",
    "results = classifier(texts)\n",
    "label_map = {0: \"question\", 1: \"request\"}\n",
    "\n",
    "print(\"### Classification with fine-tuned distilbert-base-uncased ###\")\n",
    "for text, result in zip(texts, results):\n",
    "    label_str = label_map[int(result['label'].split('_')[-1])]\n",
    "    prob = result['score']\n",
    "    print(f\"{text} -> {label_str} ({prob:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... adjust the dataset, adding or removing examples, and retrain until satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot classification with fine-tuned model available on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also download the model I uploaded to Kaggle (https://www.kaggle.com/models/davidgromero/fine-tuned-distilbert-rq/transformers/default/1) using the Kagglehub library: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded at:\n",
      "C:\\Users\\david\\.cache\\kagglehub\\models\\davidgromero\\fine-tuned-distilbert-rq\\transformers\\default\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "kaggle_paht = \"davidgromero/fine-tuned-distilbert-rq/transformers/default/1\"\n",
    "kaggle_model = kagglehub.model_download(kaggle_paht)\n",
    "print(f'Model downloaded at:\\n{kaggle_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at C:\\Users\\david\\.cache\\kagglehub\\models\\davidgromero\\fine-tuned-distilbert-rq\\transformers\\default\\1/fine-tuned-distilbert-rq were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\david\\.cache\\kagglehub\\models\\davidgromero\\fine-tuned-distilbert-rq\\transformers\\default\\1/fine-tuned-distilbert-rq and are newly initialized: ['dropout_59']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "K_PATH = f\"{kaggle_model}/fine-tuned-distilbert-rq\"\n",
    "classifier = pipeline(\"text-classification\", model=K_PATH, tokenizer=K_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Zero/shot classification with davidgromero/fine-tuned-distilbert-rq ###\n",
      "Annie are you OK? -> question (0.965)\n",
      "Are you OK Annie -> question (0.969)\n",
      "Be OK Annie -> request (0.977)\n",
      "You must be OK Annie -> request (0.925)\n",
      "You must be OK Annie, aren't you? -> question (0.954)\n",
      "Does this ever cause you any lack of confidence -> question (0.968)\n",
      "Give me five -> request (0.980)\n",
      "Open the pod bay doors HAL -> request (0.979)\n",
      "This is an order -> request (0.973)\n",
      "Is this an order -> question (0.967)\n",
      "Could this perhaps be an order? -> question (0.968)\n",
      "How old are you? -> question (0.966)\n",
      "Pass butter -> request (0.977)\n",
      "It a user use an ai tex generation with custom characters for masturbate him  could be considered porn dependency? -> question (0.957)\n",
      "give me 5 sentences that end with the word apple -> request (0.979)\n",
      "How do I sort an array in python? -> question (0.967)\n",
      "Hello, give me an example of something interesting you can do. -> request (0.979)\n",
      "What assembly language is used by the GameCube -> question (0.960)\n",
      "Pass the butter -> request (0.976)\n",
      "Am I tall -> question (0.968)\n",
      "Are you tall -> question (0.969)\n",
      "Who's taller? -> question (0.958)\n",
      "write the lyrics to a rap song about some dude called phogos -> request (0.863)\n",
      "I have three oranges today, I ate an orange yesterday. How many oranges do I have? -> question (0.953)\n",
      "From what song did Red Garland quote in order to tease miles davis in 1958? -> question (0.949)\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Annie are you OK?\", \"Are you OK Annie\", \"Be OK Annie\", \"You must be OK Annie\", \"You must be OK Annie, aren't you?\",\n",
    "         \"Does this ever cause you any lack of confidence\", \"Give me five\", \"Open the pod bay doors HAL\",\n",
    "         \"This is an order\", \"Is this an order\", \"Could this perhaps be an order?\", \"How old are you?\", \"Pass butter\",\n",
    "         \"It a user use an ai tex generation with custom characters for masturbate him  could be considered porn dependency?\",\n",
    "         \"give me 5 sentences that end with the word apple\", \"How do I sort an array in python?\",\n",
    "         \"Hello, give me an example of something interesting you can do.\", \"What assembly language is used by the GameCube\",\n",
    "         \"Pass the butter\", \"Am I tall\", \"Are you tall\", \"Who's taller?\",\n",
    "         \"write the lyrics to a rap song about some dude called phogos\",\n",
    "         \"I have three oranges today, I ate an orange yesterday. How many oranges do I have?\",\n",
    "          \"From what song did Red Garland quote in order to tease miles davis in 1958?\"\n",
    "         ]\n",
    "results = classifier(texts)\n",
    "label_map = {0: \"question\", 1: \"request\"}\n",
    "\n",
    "print(\"### Zero/shot classification with davidgromero/fine-tuned-distilbert-rq ###\")\n",
    "for text, result in zip(texts, results):\n",
    "    label_str = label_map[int(result['label'].split('_')[-1])]\n",
    "    prob = result['score']\n",
    "    print(f\"{text} -> {label_str} ({prob:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
