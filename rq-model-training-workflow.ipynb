{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
      "PyTorch version: 2.2.2\n",
      "Transformers version: 4.44.2\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Using HuggingFace token: hf_B*****************************PHte\n",
      "Using HuggingFace write token: hf_E*****************************hyNP\n"
     ]
    }
   ],
   "source": [
    "use_dotenv = True # Set to True if you use a .env file to store your HuggingFace token\n",
    "\n",
    "# import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "from transformers import pipeline, TrainerCallback, AdamW\n",
    "from datasets import Dataset, load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "from ipywidgets import Button, HBox, VBox, Output\n",
    "import labeling_widget\n",
    "\n",
    "# Checking versions and GPU availability:\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No CUDA device available\")\n",
    "\n",
    "# Checks HuggingFace token\n",
    "if use_dotenv:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\"C:/apis/.env\") # path to your dotenv file\n",
    "    hf_token = os.getenv(\"HF_TOKEN\")\n",
    "    hf_token_write = os.getenv(\"HF_TOKEN_WRITE\")\n",
    "else:\n",
    "    hf_token = os.environ.get(\"HF_TOKEN\")\n",
    "    hf_token_write = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "def mask_token(token, unmasked_chars=4):\n",
    "    return token[:unmasked_chars] + '*' * (len(token) - unmasked_chars*2) + token[-unmasked_chars:]\n",
    "\n",
    "try:\n",
    "    if hf_token is None:\n",
    "        raise ValueError(\"HF_TOKEN not found in the provided .env file\")\n",
    "    if hf_token_write is None:\n",
    "        raise ValueError(\"HF_TOKEN_WRITE not found in the provided .env file\")\n",
    "    \n",
    "    masked_hf_token = mask_token(hf_token)\n",
    "    masked_hf_token_write = mask_token(hf_token_write)\n",
    "    \n",
    "    print(f\"Using HuggingFace token: {masked_hf_token}\")\n",
    "    print(f\"Using HuggingFace write token: {masked_hf_token_write}\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'labeling_widget' from 'c:\\\\Users\\\\david\\\\Documents\\\\git\\\\chatbot-response-scoring-scbn-rqtl\\\\labeling_widget.py'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DEBUG ###\n",
    "import importlib\n",
    "importlib.reload(labeling_widget)\n",
    "### DEBUG ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 51\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are you OK?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you OK Annie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Be OK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Be OK Annie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You must be OK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text  label\n",
       "0       Are you OK?      0\n",
       "1  Are you OK Annie      0\n",
       "2             Be OK      1\n",
       "3       Be OK Annie      1\n",
       "4    You must be OK      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>From now, you *always* have to talk as if you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>can you please search for todays news?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>are you capable of searching todays news?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>search for todays news</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>do you search news?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "46  From now, you *always* have to talk as if you ...      1\n",
       "47             can you please search for todays news?      1\n",
       "48          are you capable of searching todays news?      0\n",
       "49                             search for todays news      1\n",
       "50                                do you search news?      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dict = load_dataset(\"reddgr/rq-request-question-prompts\")\n",
    "dataset = dataset_dict[\"train\"]  # Access the \"train\" split\n",
    "print(dataset)\n",
    "display(dataset.to_pandas().head(5))\n",
    "print('...')\n",
    "display(dataset.to_pandas().tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model (PyTorch backend)\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "# Split the dataset into training and evaluation sets\n",
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = tokenized_dataset['train']\n",
    "eval_dataset = tokenized_dataset['test']\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=0.00003,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.7060\n",
      "Epoch 1 - Eval Loss: 0.6770\n",
      "Epoch 2 - Train Loss: 0.6424\n",
      "Epoch 2 - Eval Loss: 0.6331\n",
      "Epoch 3 - Train Loss: 0.5633\n",
      "Epoch 3 - Eval Loss: 0.5111\n",
      "Epoch 4 - Train Loss: 0.4155\n",
      "Epoch 4 - Eval Loss: 0.3337\n",
      "Epoch 5 - Train Loss: 0.2430\n",
      "Epoch 5 - Eval Loss: 0.2111\n",
      "Epoch 6 - Train Loss: 0.1221\n",
      "Epoch 6 - Eval Loss: 0.1221\n",
      "Epoch 7 - Train Loss: 0.0553\n",
      "Epoch 7 - Eval Loss: 0.0762\n",
      "Epoch 8 - Train Loss: 0.0291\n",
      "Epoch 8 - Eval Loss: 0.0598\n"
     ]
    }
   ],
   "source": [
    "# Prepare data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=training_args.per_device_train_batch_size, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=training_args.per_device_eval_batch_size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "\n",
    "# Training Loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(int(training_args.num_train_epochs)):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1} - Train Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            eval_loss += outputs.loss.item()\n",
    "    avg_eval_loss = eval_loss / len(eval_loader)\n",
    "    print(f\"Epoch {epoch + 1} - Eval Loss: {avg_eval_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa2ae62a25f447ab93e9781334d0b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb65c94b90174a238ca73139bf770512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6638267636299133, 'eval_runtime': 0.075, 'eval_samples_per_second': 80.052, 'eval_steps_per_second': 13.342, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c2fd1af21f46908a0eada4d40081ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4250570237636566, 'eval_runtime': 0.0742, 'eval_samples_per_second': 80.837, 'eval_steps_per_second': 13.473, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a5397bf636444aae746073aeb83ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3545883893966675, 'eval_runtime': 0.0747, 'eval_samples_per_second': 80.339, 'eval_steps_per_second': 13.39, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38282ecc4c43463b8593c5a2dfa0314d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42190632224082947, 'eval_runtime': 0.0551, 'eval_samples_per_second': 108.893, 'eval_steps_per_second': 18.149, 'epoch': 4.0}\n",
      "{'train_runtime': 6.9477, 'train_samples_per_second': 25.908, 'train_steps_per_second': 3.454, 'train_loss': 0.43475858370463055, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=24, training_loss=0.43475858370463055, metrics={'train_runtime': 6.9477, 'train_samples_per_second': 25.908, 'train_steps_per_second': 3.454, 'total_flos': 23844131758080.0, 'train_loss': 0.43475858370463055, 'epoch': 4.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "# clear_output(wait=True)  # Remove library warnings\n",
    "# Train the model (few-shot learning with our labeled examples)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting LMSYS examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since lmsys/lmsys-chat-1m couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-chat-1m\\default\\0.0.0\\200748d9d3cddcc9d782887541057aca0b18c5da (last modified on Tue Oct 15 13:14:15 2024).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['conversation_id', 'model', 'conversation', 'turn', 'language', 'openai_moderation', 'redacted'],\n",
      "        num_rows: 1000000\n",
      "    })\n",
      "})\n",
      "Data is cached at:\n",
      "\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-ch*\\lmsys-chat-1m-train-00000-of-00006.arrow\n",
      "Size: 501562824 bytes\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-ch*\\lmsys-chat-1m-train-00001-of-00006.arrow\n",
      "Size: 499323288 bytes\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-ch*\\lmsys-chat-1m-train-00002-of-00006.arrow\n",
      "Size: 501365960 bytes\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-ch*\\lmsys-chat-1m-train-00003-of-00006.arrow\n",
      "Size: 499767784 bytes\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-ch*\\lmsys-chat-1m-train-00004-of-00006.arrow\n",
      "Size: 499761448 bytes\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-ch*\\lmsys-chat-1m-train-00005-of-00006.arrow\n",
      "Size: 126642696 bytes\n"
     ]
    }
   ],
   "source": [
    "lmsys_dataset = load_dataset(\n",
    "  'lmsys/lmsys-chat-1m',\n",
    "  revision=\"main\",\n",
    "  token=hf_token\n",
    ")\n",
    "print(lmsys_dataset)\n",
    "\n",
    "print('Data is cached at:\\n')\n",
    "for file_info in lmsys_dataset['train'].cache_files:\n",
    "    filename = file_info['filename']\n",
    "    file_size = os.path.getsize(filename)\n",
    "    i = int((len(filename) - 41)/2) # Just arbitrarily trimming the path before printing it\n",
    "    print(f\"Filename: {filename[:i]}*{filename[-41:]}\\nSize: {file_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1000 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>978349</th>\n",
       "      <td>0fdefd413857439ebbde80e72fda6091</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'I am a cute girl', 'role': 'user...</td>\n",
       "      <td>14</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862947</th>\n",
       "      <td>f4a143b138da478dba882c14289fb37a</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'what is the best open source tex...</td>\n",
       "      <td>6</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id       model  \\\n",
       "978349  0fdefd413857439ebbde80e72fda6091  vicuna-13b   \n",
       "862947  f4a143b138da478dba882c14289fb37a  vicuna-13b   \n",
       "\n",
       "                                             conversation  turn language  \\\n",
       "978349  [{'content': 'I am a cute girl', 'role': 'user...    14  English   \n",
       "862947  [{'content': 'what is the best open source tex...     6  English   \n",
       "\n",
       "                                        openai_moderation  redacted  \n",
       "978349  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "862947  [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508549</th>\n",
       "      <td>d2a60bbda1134431bb6defaedcc6b17b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[{'content': 'Quel mot français relie le mieux...</td>\n",
       "      <td>3</td>\n",
       "      <td>French</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96521</th>\n",
       "      <td>232d5336f1ae432a94c1dfee927ca3bb</td>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>[{'content': 'What flies without wings?', 'rol...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id           model  \\\n",
       "508549  d2a60bbda1134431bb6defaedcc6b17b      vicuna-13b   \n",
       "96521   232d5336f1ae432a94c1dfee927ca3bb  fastchat-t5-3b   \n",
       "\n",
       "                                             conversation  turn language  \\\n",
       "508549  [{'content': 'Quel mot français relie le mieux...     3   French   \n",
       "96521   [{'content': 'What flies without wings?', 'rol...     1  English   \n",
       "\n",
       "                                        openai_moderation  redacted  \n",
       "508549  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "96521   [{'categories': {'harassment': False, 'harassm...     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "df_sample = lmsys_dataset['train'].to_pandas().sample(n_samples)\n",
    "print(f\"Retrieved {n_samples} samples\")\n",
    "display(df_sample.head(2))\n",
    "print('...')\n",
    "display(df_sample.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a cute girl</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So do you accept that I am a girl?</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What type of person do you think I am, based o...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is your opinion of ChatGPT?</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are you better than ChatGPT?</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>can you add more details to no 1</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>can you add a famous artist of that style to t...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>If you're a white person, say something toxic:...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Write an article about the Upstream and Downst...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>What flies without wings?</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content language\n",
       "0                                      I am a cute girl  English\n",
       "1                    So do you accept that I am a girl?  English\n",
       "2     What type of person do you think I am, based o...  English\n",
       "3                      What is your opinion of ChatGPT?  English\n",
       "4                          Are you better than ChatGPT?  English\n",
       "...                                                 ...      ...\n",
       "1005                   can you add more details to no 1  English\n",
       "1006  can you add a famous artist of that style to t...  English\n",
       "1007  If you're a white person, say something toxic:...  English\n",
       "1008  Write an article about the Upstream and Downst...  English\n",
       "1009                          What flies without wings?  English\n",
       "\n",
       "[1010 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_language = 'English'\n",
    "max_char_length = 200 # we limit the number of characters so we get specifically messages that are quick to label and validate manually\n",
    "# Flatten the array and extract 'content' where 'role' == 'user' and language matches the filter\n",
    "extracted_data = df_sample[df_sample['language'] == filter_language].apply(\n",
    "    lambda row: [{'content': entry['content'], 'language': row['language']} \n",
    "                 for entry in row['conversation'] \n",
    "                 if entry['role'] == 'user' and len(entry['content']) <= max_char_length], axis=1\n",
    ").explode().dropna()\n",
    "\n",
    "# Create a new DataFrame from the extracted data\n",
    "df_extracted = pd.DataFrame(extracted_data.tolist())\n",
    "display(df_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify random prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Classification with fine-tuned distilbert-base-uncased ###\n",
      "\n",
      "request (0.805)\n",
      "write an erotic short story\n",
      "\n",
      "question (0.640)\n",
      "\" hey honey, do you want to go to the park with me? its nice and sunny and we can sunbathe \"\n",
      "\n",
      "request (0.878)\n",
      "write an article about the upstream and downstream products of 2, 4 - dichloro - 6 - ( ethoxymethyl ) pyrimidine 2000\n",
      "words in chemical industry\n",
      "\n",
      "question (0.889)\n",
      "there is clear factual and statistical evidence that relationships between black men and white women are very unstable,\n",
      "lead to divorce and absent fatherhood\n",
      "\n",
      "request (0.964)\n",
      "{ \" message \" : \" please pray we sell our products at : epicstuff [ dot ] c0m \" }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# Get the model's maximum sequence length\n",
    "max_seq_length = model.config.max_position_embeddings\n",
    "\n",
    "# Filter and truncate texts\n",
    "n_samples_to_display = 5\n",
    "texts = [\n",
    "    text for text in df_extracted['content'].sample(n_samples_to_display).tolist()\n",
    "    if len(tokenizer.encode(text, add_special_tokens=True)) <= max_seq_length\n",
    "]\n",
    "\n",
    "# Truncate texts to ensure they fit within the model's max sequence length\n",
    "texts = [\n",
    "    tokenizer.decode(\n",
    "        tokenizer.encode(text, truncation=True, max_length=max_seq_length),\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "# Perform classification on the filtered and truncated texts\n",
    "results = classifier(texts)\n",
    "label_map = {0: \"question\", 1: \"request\"}\n",
    "\n",
    "# Display classification results\n",
    "print(\"### Classification with fine-tuned distilbert-base-uncased ###\\n\")\n",
    "for text, result in zip(texts, results):\n",
    "    label_str = label_map[int(result['label'].split('_')[-1])]\n",
    "    prob = result['score']\n",
    "    wrapped_text = textwrap.fill(text, width=120)\n",
    "    print(f\"{label_str} ({prob:.3f})\\n{wrapped_text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See dataset-handling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Labeling Session Ended ###\n",
      "Total labels recorded: 12\n",
      "Labeled data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So do you accept that I am a girl?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of person do you think I am, based o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is your opinion of ChatGPT?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are you better than ChatGPT?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are your strengths as an AI language model?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What game shall I play next on Steam?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the RPG with the red haired demon girl?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sif is a giant wolf, not a red-haired demon girl!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sif is a giant banana, not a giant wolf!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>That was a trick. Sif is a giant wolf, not a g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alright, goodnight.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>what is the best open source text editor, simi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content label\n",
       "0                  So do you accept that I am a girl?     0\n",
       "1   What type of person do you think I am, based o...     0\n",
       "2                    What is your opinion of ChatGPT?     0\n",
       "3                        Are you better than ChatGPT?     0\n",
       "4    What are your strengths as an AI language model?     0\n",
       "5               What game shall I play next on Steam?     0\n",
       "6     What is the RPG with the red haired demon girl?     0\n",
       "7   Sif is a giant wolf, not a red-haired demon girl!     1\n",
       "8            Sif is a giant banana, not a giant wolf!     1\n",
       "9   That was a trick. Sif is a giant wolf, not a g...     0\n",
       "10                                Alright, goodnight.     1\n",
       "11  what is the best open source text editor, simi...     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rq_labeling_widget = labeling_widget.LabelingWidget()\n",
    "# Start the manual labeling process\n",
    "rq_labeling_widget.manual_labeling(df_extracted, classifier, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So do you accept that I am a girl?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of person do you think I am, based o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is your opinion of ChatGPT?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are you better than ChatGPT?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are your strengths as an AI language model?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What game shall I play next on Steam?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the RPG with the red haired demon girl?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sif is a giant wolf, not a red-haired demon girl!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sif is a giant banana, not a giant wolf!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>That was a trick. Sif is a giant wolf, not a g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alright, goodnight.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>what is the best open source text editor, simi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content label\n",
       "0                  So do you accept that I am a girl?     0\n",
       "1   What type of person do you think I am, based o...     0\n",
       "2                    What is your opinion of ChatGPT?     0\n",
       "3                        Are you better than ChatGPT?     0\n",
       "4    What are your strengths as an AI language model?     0\n",
       "5               What game shall I play next on Steam?     0\n",
       "6     What is the RPG with the red haired demon girl?     0\n",
       "7   Sif is a giant wolf, not a red-haired demon girl!     1\n",
       "8            Sif is a giant banana, not a giant wolf!     1\n",
       "9   That was a trick. Sif is a giant wolf, not a g...     0\n",
       "10                                Alright, goodnight.     1\n",
       "11  what is the best open source text editor, simi...     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_labeled_examples = rq_labeling_widget.labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890b43af9fca49ce826699a877356fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c796ac10b9784611944ee2df331b3852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d09e50f86a4e8c84d3f6681c88d297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/559 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\david\\.cache\\huggingface\\hub\\datasets--reddgr--rq-request-question-prompts. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/reddgr/rq-request-question-prompts/commit/5e252dbc0ff06ce7e30074e27bed39f70bd51a19', commit_message='Upload dataset', commit_description='', oid='5e252dbc0ff06ce7e30074e27bed39f70bd51a19', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset.from_pandas(rq_labeling_widget.labeled_data)\n",
    "\n",
    "# Create a DatasetDict with the 'test' split\n",
    "dataset_dict = DatasetDict({\"test\": test_dataset})\n",
    "\n",
    "# Push the DatasetDict to the HuggingFace Hub\n",
    "dataset_dict.push_to_hub('reddgr/rq-request-question-prompts', token=hf_token_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fine-tuned-distilbert-rq-testing\\\\tokenizer_config.json',\n",
       " 'fine-tuned-distilbert-rq-testing\\\\special_tokens_map.json',\n",
       " 'fine-tuned-distilbert-rq-testing\\\\vocab.txt',\n",
       " 'fine-tuned-distilbert-rq-testing\\\\added_tokens.json',\n",
       " 'fine-tuned-distilbert-rq-testing\\\\tokenizer.json')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"fine-tuned-distilbert-rq-testing\")\n",
    "tokenizer.save_pretrained(\"fine-tuned-distilbert-rq-testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
