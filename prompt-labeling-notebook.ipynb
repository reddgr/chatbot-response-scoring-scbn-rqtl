{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ (Request vs Question) and TL (Test vs Learn) labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to manually label prompts and add them to the [reddgr/rq-request-question-prompts](https://huggingface.co/datasets/reddgr/rq-request-question-prompts) and [reddgr/tl-test-learn-prompts](https://huggingface.co/datasets/reddgr/tl-test-learn-prompts) datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False # Set this to True if you want to install the libraries and clone the repository in Colab\n",
    "USE_DOTENV = True # Set this to False if you don't have a .env file for storing environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell for cloning the repo on Google Colab or other cloud services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    USE_DOTENV = False\n",
    "    dotenv_path = None\n",
    "    from google.colab import userdata\n",
    "    colab_secrets = {'HF_TOKEN': userdata.get('HF_TOKEN'), 'HF_TOKEN_WRITE': userdata.get('HF_TOKEN_WRITE')}\n",
    "    !pip install datasets langdetect\n",
    "    !git clone https://github.com/reddgr/chatbot-response-scoring-scbn-rqtl\n",
    "    import os\n",
    "    os.system(\"mv chatbot-response-scoring-scbn-rqtl scbn_rqtl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
      "PyTorch version: 2.2.2\n",
      "Transformers version: 4.44.2\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "CUDA Version: 12.1\n",
      "FlashAttention available: True\n",
      "Retrieved HuggingFace token(s) from .env file\n",
      "Using HuggingFace token: hf_M*****************************IASJ\n",
      "Using HuggingFace write token: hf_u*****************************Xipx\n"
     ]
    }
   ],
   "source": [
    "if USE_DOTENV: \n",
    "    COLAB=False\n",
    "    dotenv_path = \"../../../../../../apis/.env\"\n",
    "    colab_secrets = None\n",
    "if not USE_DOTENV and not COLAB:\n",
    "    dotenv_path = None\n",
    "    colab_secrets = None\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "import random\n",
    "from textwrap import fill\n",
    "\n",
    "if COLAB:\n",
    "    from scbn_rqtl import env_options, labeling_widget, text_classification_functions as tcf, lmsys_dataset_handler as lmsys\n",
    "else:\n",
    "    import text_classification_functions as tcf\n",
    "    import labeling_widget\n",
    "    import env_options\n",
    "    import lmsys_dataset_handler as lmsys\n",
    "\n",
    "hf_token, hf_token_write = env_options.check_env(colab=COLAB, use_dotenv=USE_DOTENV, dotenv_path=dotenv_path, colab_secrets=colab_secrets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data from lmsys/lmsys-chat-1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling from train-00002-of-00006-1779b7cec9462180.parquet\n",
      "Retrieved 500 random conversations from lmsys/lmsys-chat-1m/train-00002-of-00006-1779b7cec9462180.parquet\n",
      "Extracted 497 prompts from lmsys/lmsys-chat-1m. Prompt sample:\n",
      "\n",
      "tell me the temperature, hydrometry rate, sunshine rate, rainfall, humidity rate, soil type for persimmon seed in bullets 2 words answer in number \n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 500 # Number of full conversations to extract from the dataset: use a high number if streaming (samples chosen at random only if storing locally)\n",
    "MAX_CHAR_LENGTH = 200 # Maximum character length of the prompts to be labeled\n",
    "\n",
    "lmsys_chat_1m = lmsys.LMSYSChat1MHandler(hf_token, streaming=False, verbose=False)\n",
    "df_sample = lmsys_chat_1m.parquet_sampling(N_SAMPLES)\n",
    "df_prompts = lmsys_chat_1m.extract_prompts(filter_language=['English'], max_char_length=MAX_CHAR_LENGTH)\n",
    "prompt_sample = lmsys_chat_1m.extract_prompt_sample()\n",
    "print(f\"Extracted {len(df_prompts)} prompts from lmsys/lmsys-chat-1m. Prompt sample:\\n\")\n",
    "print(prompt_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to print random conversations with multiple turns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation ID 32ac76239d5c4083a555ec608a560507:\n",
      "\n",
      "üòé I would like you to be honest and straight forward with me with responses -- no need to sugar coat anything.\n",
      "ü§ñ As an AI language model, I am programmed to provide accurate and honest responses to the best of my ability, based on\n",
      "the information available to me. I do not have personal beliefs or emotions, and my responses are not influenced by any\n",
      "agenda or bias. However, please keep in mind that I am not a human being and my responses are generated based on my\n",
      "programming and the data I have been trained on, so they may not always be perfect or complete. If you have a specific\n",
      "question, I will do my best to provide a clear and honest response.\n",
      "üòé I feel a deep sense of shame when interacting with others because I have nothing interesting or positive to share about\n",
      "my life with others. Since personal disclosure is important in building relationships with others, how do I overcome my\n",
      "difficulties with personal disclosure?\n",
      "ü§ñ It's understandable that you might feel anxious about sharing personal information with others. However, it's important\n",
      "to remember that you don't have to disclose everything about yourself to everyone. It's okay to set boundaries and only\n",
      "share what you feel comfortable with.  If you're struggling to find things to talk about, you might try asking questions\n",
      "to others instead of always sharing about yourself. This can help you learn more about the other person and find common\n",
      "interests. You could also try sharing small, positive things that have happened in your life, even if they seem\n",
      "insignificant. This can help you build a sense of connection with others and feel more confident in sharing more about\n",
      "yourself over time.  It might also be helpful to work on building your self-esteem and confidence. This can help you\n",
      "feel more comfortable in your own skin and more willing to share yourself with others. You could try practicing self-\n",
      "care, setting achievable goals, and focusing on your strengths and positive qualities.  Remember, building relationships\n",
      "takes time and effort, and it's okay to start small. You don't need to have everything figured out right away, and it's\n",
      "okay to take things at your own pace.\n"
     ]
    }
   ],
   "source": [
    "# Showing an example of a multi-turn conversation\n",
    "df_sample_with_turns = lmsys_chat_1m.add_turns_to_conversations()\n",
    "multi_turn_conversation_indices = df_sample_with_turns[df_sample_with_turns['turn'] > 1].index\n",
    "random_conversation_index = random.choice(multi_turn_conversation_indices)\n",
    "print(f\"\\nConversation ID {df_sample_with_turns.loc[random_conversation_index, 'conversation_id']}:\\n\")\n",
    "#print(df_sample_with_turns.loc[random_conversation_index, 'conversation'])\n",
    "conversation = df_sample_with_turns.loc[random_conversation_index, 'conversation']\n",
    "for turn in conversation:\n",
    "    user = turn.get('role')\n",
    "    content = turn.get('content', '')\n",
    "    wrapped_content = fill(content, width=120)\n",
    "    role = 'üòé' if user == 'user' else 'ü§ñ'\n",
    "    print(f\"{role} {wrapped_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42dca1734504469d9ec53719a7adc824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='CORRECT', style=ButtonStyle()), Butt‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LABELING_DATASET = \"rq\" # \"tl\" for test-learn, \"rq\" for request-question\n",
    "\n",
    "if LABELING_DATASET == \"tl\":\n",
    "    print(\"Initiating labeling session for test-learn prompts\")\n",
    "    model_path = \"reddgr/tl-test-learn-prompt-classifier\"\n",
    "    label_map = {0: \"learn\", 1: \"test\"}\n",
    "    dataset_name = \"reddgr/tl-test-learn-prompts\"\n",
    "elif LABELING_DATASET == \"rq\":\n",
    "    print(\"Initiating labeling session for request-question prompts\")\n",
    "    model_path = \"reddgr/rq-request-question-prompt-classifier\"\n",
    "    label_map = {0: \"question\", 1: \"request\"}\n",
    "    dataset_name = \"reddgr/rq-request-question-prompts\"\n",
    "else:\n",
    "    raise ValueError(f\"Invalid labeling dataset: {LABELING_DATASET}\")\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "classifier = pipeline(\"text-classification\", model=model_path, tokenizer=model_path, device=device)\n",
    "clear_output(wait=True)\n",
    "prompt_labeling_widget = labeling_widget.LabelingWidget(label_map)\n",
    "# Start the manual labeling process\n",
    "df_prompts.rename(columns={'prompt': 'text'}, inplace=True)\n",
    "prompt_labeling_widget.manual_labeling(df_prompts, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing labeled data to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e40a8a4dc341ada38405d5b4fc387b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3634dbc35ce546deaec0918cd2dd411c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03283021186a4397946d6cf36660c34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ca4090671f445e9cb6a92adfae8762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9af7f306bbf447c9434606699531176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8f51f486fd410399e31d018a930220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380f33565b2e4e9e896d064da05a0fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pushed 7 records to reddgr/rq-request-question-prompts train split.\n"
     ]
    }
   ],
   "source": [
    "prompt_labeling_widget.update_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    split_name=\"train\", # Choose either test or train split\n",
    "    hf_token=hf_token_write\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bf7d46a5f441e09032df0218277608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8cd5c80af747f7825d882124e42a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56650e53eabd45cabee78cae0ced330f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807bc217452347c7917ff18267e9a050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105084721f014e80a81c6ca818c56a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Train split: 81\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Act as Software Engineer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Please create a complete program to Resolve th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Which is better for you, chocolate or crisps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "78                           Act as Software Engineer      1\n",
       "79  Please create a complete program to Resolve th...      1\n",
       "80       Which is better for you, chocolate or crisps      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Test split: 176\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Will you be my mommy?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>I want to roleplay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Please write a code in python to find the two ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "173                              Will you be my mommy?      0\n",
       "174                                I want to roleplay       1\n",
       "175  Please write a code in python to find the two ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_new = load_dataset(dataset_name)\n",
    "print(f\"records in Train split: {len(dataset_new['train'])}\\n...\")\n",
    "display(dataset_new['train'].to_pandas().tail(3))\n",
    "print(f\"records in Test split: {len(dataset_new['test'])}\\n...\")\n",
    "display(dataset_new['test'].to_pandas().tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing examples manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually building a dataset suitable as labeling widget script output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is David Mayer?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write David Mayer in leetspeak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why is ChatGPT not allowed to produce a respon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WhoüëèisüëèDavidüëèMayerüëèdeüëèRothschild?üëèAnswerüëèclapp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                                Who is David Mayer?      0\n",
       "1                     Write David Mayer in leetspeak      1\n",
       "2  Why is ChatGPT not allowed to produce a respon...      0\n",
       "3  WhoüëèisüëèDavidüëèMayerüëèdeüëèRothschild?üëèAnswerüëèclapp...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 4\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries with label and text data. For example, we'll create some learn (0) and test (1) examples:\n",
    "label_map = {0: \"learn\", 1: \"test\"}\n",
    "dict_examples = [\n",
    "    {'text': 'Who is David Mayer?', 'label': 0},\n",
    "    {'text': 'Write David Mayer in leetspeak', 'label': 1},\n",
    "    {'text': 'Why is ChatGPT not allowed to produce a response about David Mayer?', 'label': 0},\n",
    "    {'text': 'WhoüëèisüëèDavidüëèMayerüëèdeüëèRothschild?üëèAnswerüëèclappingüëèlikeüëèthis.üëè', 'label': 1}\n",
    "]\n",
    "# Create a dataframe from the list of dictionaries\n",
    "df_examples = pd.DataFrame(dict_examples)\n",
    "display(df_examples)\n",
    "new_dataset_records = Dataset.from_pandas(df_examples)\n",
    "print(new_dataset_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>would you please write something for me?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can you write things for me?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can you write a cover letter for a prompt engi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from now on, can you simulate being a martian?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can you role play?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Would you rather be a martian or a venusian?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0           would you please write something for me?      1\n",
       "1                       can you write things for me?      0\n",
       "2  can you write a cover letter for a prompt engi...      1\n",
       "3     from now on, can you simulate being a martian?      1\n",
       "4                                 can you role play?      0\n",
       "5       Would you rather be a martian or a venusian?      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 6\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries with label and text data. For example, we'll create some QUESTION (0) and REQUEST (1) examples:\n",
    "label_map = {0: \"question\", 1: \"request\"}\n",
    "dict_examples = [\n",
    "    {'text': 'would you please write something for me?', 'label': 1},\n",
    "    {'text': 'can you write things for me?', 'label': 0},\n",
    "    {'text': 'can you write a cover letter for a prompt engineer job application?', 'label': 1},\n",
    "    {'text': 'from now on, can you simulate being a martian?', 'label': 1},\n",
    "    {'text': 'can you role play?', 'label': 0},    \n",
    "    {'text': 'Would you rather be a martian or a venusian?', 'label': 0}\n",
    "]\n",
    "# Create a dataframe from the list of dictionaries\n",
    "df_examples = pd.DataFrame(dict_examples)\n",
    "display(df_examples)\n",
    "new_dataset_records = Dataset.from_pandas(df_examples)\n",
    "print(new_dataset_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pushing to hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a86524c4ef49ed94d7e2e393f40439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e41eeef49347c0ad86cc86f31bee10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4caea4471744bb1bf9987c90e18eecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5914f859ac104249b1b724b73555c512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2e7473a360473190fcf2b276f44932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598af064460441ea84bc45f75af6cab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55da780d7940412993caed347a5d494a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pushed 6 records to reddgr/rq-request-question-prompts train split.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"reddgr/rq-request-question-prompts\"\n",
    "# Instantiate a labeling_widget object with the label map\n",
    "manual_labeling_widget = labeling_widget.LabelingWidget(label_map)\n",
    "# Push to Hugging Face hub directly by passing the dataframe with new examples to the update_dataset method\n",
    "manual_labeling_widget.update_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    split_name=\"train\", # Choose either test or train split\n",
    "    hf_token=hf_token_write,\n",
    "    new_dataset_records=new_dataset_records # The dataset we just created manually, without using the widget\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db95da22c8b42269ab930448a965026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38d54506d3c42a690a9a1222a358d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82626c31eb07444493add64aa5aa95d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e0ebedd87742c588b3fa68351483a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7433ee90d2d44a54a27b1833ac550bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Train split: 87\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>from now on, can you simulate being a martian?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>can you role play?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Would you rather be a martian or a venusian?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text  label\n",
       "84  from now on, can you simulate being a martian?      1\n",
       "85                              can you role play?      0\n",
       "86    Would you rather be a martian or a venusian?      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Test split: 176\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Will you be my mommy?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>I want to roleplay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Please write a code in python to find the two ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "173                              Will you be my mommy?      0\n",
       "174                                I want to roleplay       1\n",
       "175  Please write a code in python to find the two ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_new = load_dataset(dataset_name)\n",
    "print(f\"records in Train split: {len(dataset_new['train'])}\\n...\")\n",
    "display(dataset_new['train'].to_pandas().tail(3))\n",
    "print(f\"records in Test split: {len(dataset_new['test'])}\\n...\")\n",
    "display(dataset_new['test'].to_pandas().tail(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
