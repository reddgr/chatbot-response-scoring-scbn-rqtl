{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook downloads raw conversations and votes data from the official LMSYS Chatbot Arena repository on HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HuggingFace token required for using lmsys/lmsys-chat-1m dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: hf_B*****************************PHte\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dotenv file should contain:\n",
    "HF_TOKEN=\"YOURHFTOKEN\"\n",
    "'''\n",
    "load_dotenv(\"C:/apis/.env\") # path to your dotenv file\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "unmasked_chars = 4\n",
    "masked_token = hf_token[:unmasked_chars] + '*' * (len(hf_token) - unmasked_chars*2) + hf_token[-unmasked_chars:]\n",
    "print(f\"Token: {masked_token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloads the dataset (2.44 GB as of August 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\datasets\\load.py:2566: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41680b70a76d443da6ae179bdd540418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94757360707d4306aec48a7a2e7e267e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0166fcee67340e4815d377e54799e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/247M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ad1b8477f84790b106716cc87f4f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/250M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b6755c67344f468f73de6049fed555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/247M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3e0114005c47bba0ebb2bd8b3c4e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba1f2be00734e31ad6ac52da77ab08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcde64b1724487b9c9d447a5d54a717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['conversation_id', 'model', 'conversation', 'turn', 'language', 'openai_moderation', 'redacted'],\n",
      "        num_rows: 1000000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "  'lmsys/lmsys-chat-1m',\n",
    "  revision=\"main\",\n",
    "  use_auth_token=hf_token\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation</th>\n",
       "      <th>turn</th>\n",
       "      <th>language</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>redacted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>467254</th>\n",
       "      <td>f57ad42158ac407e9ce8147bd219262f</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>[{'content': 'Generate a skeleton for a multif...</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491720</th>\n",
       "      <td>03d0ed35909e46fab341c292ec6e92d5</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>[{'content': 'Please correct the grammar in th...</td>\n",
       "      <td>4</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621380</th>\n",
       "      <td>2e252b44e0324e92b71d86740d536f75</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>[{'content': 'Describe how a cyberpuk android ...</td>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>[{'categories': {'harassment': False, 'harassm...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id         model  \\\n",
       "467254  f57ad42158ac407e9ce8147bd219262f    chatglm-6b   \n",
       "491720  03d0ed35909e46fab341c292ec6e92d5  mpt-30b-chat   \n",
       "621380  2e252b44e0324e92b71d86740d536f75    vicuna-33b   \n",
       "\n",
       "                                             conversation  turn language  \\\n",
       "467254  [{'content': 'Generate a skeleton for a multif...     3  English   \n",
       "491720  [{'content': 'Please correct the grammar in th...     4  English   \n",
       "621380  [{'content': 'Describe how a cyberpuk android ...     1  English   \n",
       "\n",
       "                                        openai_moderation  redacted  \n",
       "467254  [{'categories': {'harassment': False, 'harassm...     False  \n",
       "491720  [{'categories': {'harassment': False, 'harassm...      True  \n",
       "621380  [{'categories': {'harassment': False, 'harassm...      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nSample data:\")\n",
    "display(dataset['train'].to_pandas().sample(n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample conversation:\n",
      "[{'content': 'vector c++ дуали из вектора элемент равный элементу', 'role': 'user'}\n",
      " {'content': 'В C++ вы можете найти дубликаты в векторе следующим образом:\\n\\n```cpp\\n#include <vector>\\n#include <algorithm>\\n\\nstd::vector<int> findDuplicates(std::vector<int> nums) {\\n    std::vector<int> duplicates;\\n    std::sort(nums.begin(), nums.end());\\n    for (int i = 0; i < nums.size() - 1; i++) {\\n        if (nums[i] == nums[i + 1]) {\\n            duplicates.push_back(nums[i]);\\n            i++;\\n        }\\n    }\\n    return duplicates;\\n}\\n\\nint main() {\\n    std::vector<int> nums = {1, 2, 3, 1, 2, 4};\\n    std::vector<int> duplicates = findDuplicates(nums);\\n    // duplicates is {1, 2}\\n}\\n```\\n\\nЭтот код:\\n\\n1. Сортирует вектор nums\\n2. Проходит по отсортированному вектору и ищет повторяющиеся элементы\\n3. Добавляет найденные дубликаты в результирующий вектор duplicates\\n4. Возвращает вектор найденных дубликатов\\n\\nТаким образом, для входного вектора [1, 2, 3, 1, 2, 4] результатом будет вектор [1, 2] с найденными дубликатами.', 'role': 'assistant'}\n",
      " {'content': 'vector c++ дуали из вектора элемент равный элементу и удали из вектора', 'role': 'user'}\n",
      " {'content': 'Для поиска и удаления дубликатов из вектора в C++ можно использовать следующий код:\\n\\n```cpp\\n#include <vector>\\n#include <algorithm>\\n\\nvoid removeDuplicates(std::vector<int>& nums) {\\n    std::sort(nums.begin(), nums.end());\\n    int i = 0;\\n    for (int j = 1; j < nums.size(); j++) {\\n        if (nums[i] != nums[j]) {\\n            i++;\\n            nums[i] = nums[j];\\n        }\\n    }\\n    nums.erase(nums.begin() + i + 1, nums.end());\\n}\\n\\nint main() {\\n    std::vector<int> nums = {1, 2, 3, 1, 2, 4};\\n    removeDuplicates(nums);\\n    // nums is now {1, 2, 3, 4}\\n}\\n```\\n\\nЭтот код:\\n\\n1. Сортирует вектор nums\\n2. Использует два указателя i и j - i указывает на следующий свободный индекс, j проходит по вектору \\n3. Если nums[i] != nums[j], то элемент nums[j] не является дубликатом, и мы копируем его в nums[i] и увеличиваем i\\n4. В конце мы удаляем все элементы после i, используя метод erase\\n\\nТаким образом, из входного вектора [1, 2, 3, 1, 2, 4] получится вектор [1, 2, 3, 4] без дубликатов.', 'role': 'assistant'}\n",
      " {'content': 'void eraseNet(vector<NetworkBehaviour *> list,NetworkBehaviour * player){\\n\\nудалить такой же елемент вектора', 'role': 'user'}\n",
      " {'content': 'В C++ вы можете удалить все вхождения конкретного элемента из вектора следующим образом:\\n\\n```cpp\\nvoid eraseNet(vector<NetworkBehaviour *> &list, NetworkBehaviour *player) {\\n    list.erase(remove(list.begin(), list.end(), player), list.end()); \\n}\\n```\\n\\nЭтот код:\\n\\n1. Использует std::remove для поиска всех вхождений элемента player в векторе list и \"смещения\" всех других элементов влево\\n2. Затем использует list.erase для удаления всех элементов после последнего смещенного элемента\\n\\nТаким образом, все вхождения элемента player будут удалены из вектора list.\\n\\nНапример, если list = {1, 2, 3, 2, 4, 2} и player = 2, то после вызова eraseNet list станет {1, 3, 4}', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample conversation:\")\n",
    "random_sample = dataset['train'].to_pandas().sample(n=1)\n",
    "conversation = random_sample['conversation'].values[0]\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is cached at:\n",
      "\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-chat-1m\\default\\0.0.0\\200748d9d3cddcc9d782887541057aca0b18c5da\\lmsys-chat-1m-train-00000-of-00006.arrow\n",
      "Size: 501562824 bytes\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-chat-1m\\default\\0.0.0\\200748d9d3cddcc9d782887541057aca0b18c5da\\lmsys-chat-1m-train-00001-of-00006.arrow\n",
      "Size: 499323288 bytes\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-chat-1m\\default\\0.0.0\\200748d9d3cddcc9d782887541057aca0b18c5da\\lmsys-chat-1m-train-00002-of-00006.arrow\n",
      "Size: 501365960 bytes\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-chat-1m\\default\\0.0.0\\200748d9d3cddcc9d782887541057aca0b18c5da\\lmsys-chat-1m-train-00003-of-00006.arrow\n",
      "Size: 499767784 bytes\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-chat-1m\\default\\0.0.0\\200748d9d3cddcc9d782887541057aca0b18c5da\\lmsys-chat-1m-train-00004-of-00006.arrow\n",
      "Size: 499761448 bytes\n",
      "Filename: C:\\Users\\david\\.cache\\huggingface\\datasets\\lmsys___lmsys-chat-1m\\default\\0.0.0\\200748d9d3cddcc9d782887541057aca0b18c5da\\lmsys-chat-1m-train-00005-of-00006.arrow\n",
      "Size: 126642696 bytes\n"
     ]
    }
   ],
   "source": [
    "print('Data is cached at:\\n')\n",
    "for file_info in dataset['train'].cache_files:\n",
    "    filename = file_info['filename']\n",
    "    file_size = os.path.getsize(filename)\n",
    "    print(f\"Filename: {filename}\\nSize: {file_size} bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
